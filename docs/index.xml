<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>DSG | IIT Roorkee</title>
    <link>/</link>
    <description>Recent content on DSG | IIT Roorkee</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Feb 2020 23:40:49 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ChebNet: CNN on Graphs with Fast Localized Spectral Filtering</title>
      <link>/blogs/chebnet/</link>
      <pubDate>Sat, 01 Feb 2020 23:40:49 +0000</pubDate>
      
      <guid>/blogs/chebnet/</guid>
      <description>MotivationAs a part of this blog series, this time we&amp;rsquo;ll be looking at a spectral convolution technique introduced in the paper by M.</description>
    </item>
    
    <item>
      <title>A Review : Graph Convolutional Networks (GCN)</title>
      <link>/blogs/gcn/</link>
      <pubDate>Wed, 01 Jan 2020 23:40:49 +0000</pubDate>
      
      <guid>/blogs/gcn/</guid>
      <description>IntroductionGraphsWhom are we kidding! You may skip this section if you know what graphs are.</description>
    </item>
    
    <item>
      <title>Clustering Described</title>
      <link>/blogs/clustering/</link>
      <pubDate>Wed, 01 Jan 2020 23:40:49 +0000</pubDate>
      
      <guid>/blogs/clustering/</guid>
      <description>After Supervised Learning algorithms, it’s time to have a look at the most popular Unsupervised method.</description>
    </item>
    
    <item>
      <title>Graph SAGE(SAmple and aggreGatE) : Inductive Learning on Graphs</title>
      <link>/blogs/graphsage/</link>
      <pubDate>Wed, 01 Jan 2020 23:40:49 +0000</pubDate>
      
      <guid>/blogs/graphsage/</guid>
      <description>IntroductionIn the previous blogs, we covered GCN and DeepWalk, which are methods to generate node embeddings.</description>
    </item>
    
    <item>
      <title>Understanding Deepwalk</title>
      <link>/blogs/deepwalk/</link>
      <pubDate>Wed, 01 Jan 2020 23:40:49 +0000</pubDate>
      
      <guid>/blogs/deepwalk/</guid>
      <description>This is the first in this blog series Explained: Graph Representation Learning and to discuss extraction useful graph features and node embeddings by considering the topology of the network graph using machine learning, this blog deals with Deep Walk.</description>
    </item>
    
    <item>
      <title>Understanding Graph Attention Networks (GAT)</title>
      <link>/blogs/gat/</link>
      <pubDate>Wed, 01 Jan 2020 23:40:49 +0000</pubDate>
      
      <guid>/blogs/gat/</guid>
      <description>Understanding Graph Attention Networks (GAT)This is 4th in the series of blogs Explained: Graph Representation Learning.</description>
    </item>
    
    <item>
      <title>Adversarial Lab</title>
      <link>/work/adversarial_lab/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/work/adversarial_lab/</guid>
      <description>Adversarial Lab This project is a Web-based Tool for visualisation and generation of adversarial examples by attacking ImageNet Models like VGG, AlexNet, ResNet etc.</description>
    </item>
    
    <item>
      <title>d2l-pytorch</title>
      <link>/work/d2l-pytorch/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/work/d2l-pytorch/</guid>
      <description>d2l-pytorch This project is adapted from the original Dive Into Deep Learning book by Aston Zhang, Zachary C.</description>
    </item>
    
    <item>
      <title>DSG Shrisht</title>
      <link>/events/event1/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/events/event1/</guid>
      <description>Consectur in Bibendum </description>
    </item>
    
    <item>
      <title>Event-2</title>
      <link>/events/event2/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/events/event2/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Event-3</title>
      <link>/events/event3/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/events/event3/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Event-4</title>
      <link>/events/event4/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/events/event4/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Event-5</title>
      <link>/events/event5/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/events/event5/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Event-6</title>
      <link>/events/event6/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/events/event6/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Explained: Graph Representation Learning</title>
      <link>/work/graph_nets/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/work/graph_nets/</guid>
      <description>This project is a supplement to our blog series Explained: Graph Representation Learning. The following major papers and corresponding blogs have been covered as part of the series and we look to add blogs on a few other significant works in the field.</description>
    </item>
    
    <item>
      <title>Eye In The Sky: Image Segmentation Challenge Inter IIT 2019</title>
      <link>/work/eye-in-the-sky-image_segmentation_challenge/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/work/eye-in-the-sky-image_segmentation_challenge/</guid>
      <description>This is the winning code for &amp;ldquo;Eye In The Sky&amp;rdquo; Satellite Image Segmentation Competetion as a part of Inter-IIT Tech Meet 2019 hosted by IIT Bombay.</description>
    </item>
    
    <item>
      <title>Number Plate Detection</title>
      <link>/work/number_plate_detection/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/work/number_plate_detection/</guid>
      <description>Number Plate Detection System This project aims to detect vehicles entering the campus of IIT Roorkee, recording the Number Plates for security purposes.</description>
    </item>
    
    <item>
      <title>Reinforcement Learning 2048</title>
      <link>/work/rl_2048/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/work/rl_2048/</guid>
      <description>Q Learning Agent to Play 2048 Implementation of deep Q-network to play the game 2048 using Keras.</description>
    </item>
    
    <item>
      <title>Sarcasm Detection</title>
      <link>/work/sarcasm_detection/</link>
      <pubDate>Sun, 01 Dec 2019 23:40:49 +0000</pubDate>
      
      <guid>/work/sarcasm_detection/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Roadmap To Data Science</title>
      <link>/blogs/roadmap_to_datascience/</link>
      <pubDate>Sun, 04 Aug 2019 23:40:49 +0000</pubDate>
      
      <guid>/blogs/roadmap_to_datascience/</guid>
      <description>In the 21st century, computer science advancement, development of intelligent machines and generation of immense amounts of data has led to the development of new fields of study, buzzwords, Data Science and Machine Learning.</description>
    </item>
    
    <item>
      <title>GodNet: A Neural Network Which Can Predict Your Future?</title>
      <link>/blogs/godnet/</link>
      <pubDate>Wed, 27 Mar 2019 23:40:49 +0000</pubDate>
      
      <guid>/blogs/godnet/</guid>
      <description>“Have you ever questioned the nature of your reality, Dolores?” — Westworld. “Are you living in a computer simulation?</description>
    </item>
    
    <item>
      <title>Visualizing Loss Functions</title>
      <link>/work/visualizing-loss-functions/</link>
      <pubDate>Sat, 01 Dec 2018 23:40:49 +0000</pubDate>
      
      <guid>/work/visualizing-loss-functions/</guid>
      <description>Visualising different loss and optimisation functions using Autoencoder. The aim of the project was to reconstruct images with the help of Autoencoders to visualise the difference in output when different loss or optimisation functions are used.</description>
    </item>
    
    <item>
      <title>Neural Style Transfer</title>
      <link>/work/neural_style_transfer/</link>
      <pubDate>Fri, 01 Dec 2017 23:40:49 +0000</pubDate>
      
      <guid>/work/neural_style_transfer/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Project-6</title>
      <link>/work/project6/</link>
      <pubDate>Fri, 01 Dec 2017 23:40:49 +0000</pubDate>
      
      <guid>/work/project6/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Project-7</title>
      <link>/work/project7/</link>
      <pubDate>Fri, 01 Dec 2017 23:40:49 +0000</pubDate>
      
      <guid>/work/project7/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Project-8</title>
      <link>/work/project8/</link>
      <pubDate>Fri, 01 Dec 2017 23:40:49 +0000</pubDate>
      
      <guid>/work/project8/</guid>
      <description>Consectur in Bibendum Totam rem aperiam eaque ipsa quae illo inventore veritatis et quasi architebetea.vitae dicta sunt explicabo.</description>
    </item>
    
    <item>
      <title>Word Embedding</title>
      <link>/blogs/word_embeddings/</link>
      <pubDate>Sun, 15 Oct 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/word_embeddings/</guid>
      <description>What are word embeddings? Why we use word embeddings? Before going into details. lets see some example :</description>
    </item>
    
    <item>
      <title>Loss Functions and Optimization Algorithms. Demystified.</title>
      <link>/blogs/loss_functions_and_optimization_algorithms_demystified/</link>
      <pubDate>Fri, 29 Sep 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/loss_functions_and_optimization_algorithms_demystified/</guid>
      <description>The choice of Optimisation Algorithms and Loss Functions for a deep learning model can play a big role in producing optimum and faster results.</description>
    </item>
    
    <item>
      <title>Artistic Style Transfer with Convolutional Neural Network</title>
      <link>/blogs/style_transfer_with_cnn/</link>
      <pubDate>Mon, 04 Sep 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/style_transfer_with_cnn/</guid>
      <description>We all have used apps like Prisma and Lucid, but ever wondered how these things works?</description>
    </item>
    
    <item>
      <title>Baby steps with Tensoflow #2</title>
      <link>/blogs/baby_steps_with_tf_part2/</link>
      <pubDate>Sat, 17 Jun 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/baby_steps_with_tf_part2/</guid>
      <description>In this blog we will understand how to use Tensoflow for Linear and Logistic Regression. I hope you have read 1st blog of this series, if not please give it a read.</description>
    </item>
    
    <item>
      <title>Convolutional Neural Network with TensorFlow Implementation</title>
      <link>/blogs/cnn_with_tf/</link>
      <pubDate>Sat, 17 Jun 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/cnn_with_tf/</guid>
      <description>When you hear about deep learning breaking a new technological barrier, Convolutional Neural Networks are involved most of the times.</description>
    </item>
    
    <item>
      <title>Baby steps with Tensorflow #1</title>
      <link>/blogs/baby_steps_with_tf_part1/</link>
      <pubDate>Thu, 01 Jun 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/baby_steps_with_tf_part1/</guid>
      <description>Deep Learning is a Mandate for Humans, Not Just Machines — Andrew Ng Yes, Deep learning is a next big thing.</description>
    </item>
    
    <item>
      <title>Logistic Regression. Simplified.</title>
      <link>/blogs/logistic_regression/</link>
      <pubDate>Thu, 18 May 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/logistic_regression/</guid>
      <description>After the basics of Regression, it’s time for basics of Classification. And, what can be easier than Logistic Regression!</description>
    </item>
    
    <item>
      <title>Placement Experience.</title>
      <link>/blogs/placement_experience/</link>
      <pubDate>Thu, 18 May 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/placement_experience/</guid>
      <description>Placement season is like GOT, you never know what will happen in the next episode.</description>
    </item>
    
    <item>
      <title>Singular Value Decomposition. Elucidated.</title>
      <link>/blogs/svd/</link>
      <pubDate>Thu, 18 May 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/svd/</guid>
      <description>Not this SVD :P
Mathematics is building block of Machine learning. I know math is hard to understand but it is much needed as well.</description>
    </item>
    
    <item>
      <title>Data Science Congress. Something legendary.</title>
      <link>/blogs/data_science_congress/</link>
      <pubDate>Wed, 17 May 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/data_science_congress/</guid>
      <description>I know. You know. Everybody knows. What?
 India. Research. Data Science. They hardly go together.</description>
    </item>
    
    <item>
      <title>Regularization. Clarified.</title>
      <link>/blogs/regularization_clarified/</link>
      <pubDate>Sun, 02 Apr 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/regularization_clarified/</guid>
      <description>The end is near. No, not the world, but the 12A12D series. After Linear Regression, it’s time to add more DS flavour.</description>
    </item>
    
    <item>
      <title>Decision Trees. Decoded.</title>
      <link>/blogs/decision_trees_decoded/</link>
      <pubDate>Wed, 22 Mar 2017 23:40:49 +0000</pubDate>
      
      <guid>/blogs/decision_trees_decoded/</guid>
      <description>It’s time to give the Algorithm series, an informative start. Here, we start with one of the most famous category i.</description>
    </item>
    
    <item>
      <title>How To Setup Timer Hugo</title>
      <link>/blogs/installation/</link>
      <pubDate>Tue, 01 Dec 2015 23:40:49 +0000</pubDate>
      
      <guid>/blogs/installation/</guid>
      <description>Install this template by following those simple steps: STEP-1 : Hugo installation Check this link below for install hugo on your computer.</description>
    </item>
    
  </channel>
</rss>